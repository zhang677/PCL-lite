test_name: G_0_9_01
inputs:
  - name: E0
    dtype: fp32
    dims: [M, N]
    data_gen: torch.rand
  - name: E1
    dtype: Buffer(fp32, [D])
    dims: [M, N]
    data_gen: torch.rand

fns:
  - name: ExpMaxDiff
    apply: |
      m_t, e_t, d_t = state # scalar, scalar, scalar
      s_t = input[0]
      m_next = torch.max(m_t, s_t)
      dm_next = m_t - m_next
      e_next = torch.exp(s_t - m_next)
      d_next = torch.exp(dm_next)
      return [m_next, e_next, d_next]
    init: [-inf, 0, 0]
    input_dtype: fp32
    output_dtype: [fp32, fp32, fp32]
    func_name: fn_expmaxdiff
  
  - name: GetSecondThird
    apply: |
      return [input[1], input[2]]
    input_dtype: [fp32, fp32, fp32]
    output_dtype: [fp32, fp32]
    func_name: fn_getsecondthird

  - name: WeightedSumSingle
    apply: |
      e_t, d_t = input
      r_t = state[0]
      return [r_t * d_t + e_t]
    init: [0]
    input_dtype: [fp32, fp32]
    output_dtype: fp32
    func_name: fn_wssingle
  
  - name: WeightedSumDouble
    apply: |
      v_t, e_t, d_t = input
      return [state[0] * d_t + e_t * v_t]
    init: [0]
    input_dtype: ["Buffer(fp32, [D])", fp32, fp32]
    output_dtype: Buffer(fp32, [D])
    func_name: fn_wsdouble

  - name: Div
    apply: |
      r_t, l_t = input
      return [l_t / r_t.unsqueeze(-1)]
    input_dtype: [fp32, "Buffer(fp32, [D])"]
    output_dtype: Buffer(fp32, [D])
    func_name: fn_div

outputs:
  - name: S0
    dtype: fp32
    dims: [D, N]
    data_transform:
      - |
        torch.bmm(torch.softmax(input_data['E0'], 1).unsqueeze(1), input_data['E1']).squeeze(1)

impl: |
  E3 = step.Scan(fn=fn_expmaxdiff, b=1).apply(E0)
  E4 = step.Map(fn=fn_getsecondthird).apply(E3)
  E5, E6 = step.Copy().apply(E4)
  E7 = step.Accum(fn=fn_wssingle, b=1).apply(E5)
  E8 = step.Zip().apply((E1, E6))
  E9 = step.Accum(fn=fn_wsdouble, b=1).apply(E8)
  E10 = step.Zip().apply((E7, E9))
  E11  = step.Map(fn=fn_div).apply(E10)
  E2 = step.Streamify().apply(E11)
  return E2
  