test_name: G_0_13_02
global: |
  E_value = 3
  ctx[E] = E_value
  softmax = torch.nn.Softmax(dim=-1)

inputs:
  - name: E0
    dtype: fp32
    dims: [K, M]
    data_gen: torch.randn

parameters:
  - name: Wg
    dtype: fp32
    dims: [E, K]
    data_gen: torch.randn

fns:
  - name: Gate
    apply: |
      return [softmax(input[0] @ input_data['Wg'])]
    input_dtype: Buffer(fp32, [K])
    output_dtype: Buffer(fp32, [E])
    func_name: fn_gate
  
  - name: Transpose
    apply: |
      return [input[0].T]
    input_dtype: Buffer(fp32, [E, M])
    output_dtype: Buffer(fp32, [M, E])
    func_name: fn_transpose_0
  
  - name: Transpose
    apply: |
      return [input[0].T]
    input_dtype: Buffer(Multihot(fp32, M), [E])
    output_dtype: Buffer(Multihot(fp32, E), [M])
    func_name: fn_transpose_1
  
  - name: Top3
    apply: |
      _, indices = torch.topk(input[0], 3, dim=0)
      multihot = torch.zeros_like(input[0], dtype=torch.float32)
      multihot.scatter_(0, indices, 1.0)
      return [multihot]
    input_dtype: Buffer(fp32, [M])
    output_dtype: Multihot(fp32, M)
    func_name: fn_top3

outputs:
  - name: S0
    dtype: Multihot(fp32, E)
    dims: [M]
    data_transform: 
      - |
        affinity = softmax(input_data['E0'] @ input_data['Wg'])
        _, indices = torch.topk(affinity, 3, dim=0)
        multihot = torch.zeros_like(affinity, dtype=torch.float32)
        multihot.scatter(0, indices, 1.0)
  - name: S1
    dtype: Buffer(fp32, [E])
    dims: [M]
    data_transform:
      - |
        affinity
    