test_name: G_0_7_01
global: |
  E_value = 2
  ctx[E] = E_value
  sigmoid = torch.nn.Sigmoid()
  gelu = torch.nn.GELU()

inputs:
  - name: E0
    dtype: fp32
    dims: [D, N, M]
    data_gen: torch.randn
  - name: E1
    dtype: Multihot(fp32, E)
    dims: [N, M]
    min: 1
    max: 1

parameters:
  - name: W
    dtype: fp32
    dims: [D, D]
    data_gen: torch.randn
  - name: Wg
    dtype: fp32
    dims: [D]
    data_gen: torch.randn

fns:
  - name: Expert0
    apply: |
      return [input[1] * gelu(input[0] @ input_data['W']) + input[0]]
    input_dtype: ["Buffer(fp32, [D])", fp32]
    output_dtype: Buffer(fp32, [D])
    func_name: fn_expert0
  - name: Expert1
    apply: |
      return [input[0]]
    input_dtype: ["Buffer(fp32, [D])", fp32]
    output_dtype: Buffer(fp32, [D])
    func_name: fn_expert1
  - name: Affinity
    apply: |
      return [sigmoid(input[0] @ input_data['Wg'])]
    input_dtype: Buffer(fp32, [D])
    output_dtype: fp32
    func_name: fn_affinity
  - name: Sum
    apply: |
      return [state[0] + input[0]]
    init: [0]
    input_dtype: Buffer(fp32, [D])
    output_dtype: Buffer(fp32, [D])
    func_name: fn_sum

outputs:
  - name: S0
    dtype: Buffer(fp32, [D])
    dims: [N, M]
    data_transform:
      - |
        E0_data = input_data['E0'] 
        score = input_data['E1'][:, :, 0].unsqueeze(-1)
        affinity = sigmoid(E0_data @ input_data['Wg']).unsqueeze(-1)
        (affinity * (gelu(E0_data @ input_data['W'])) + E0_data) * score + E0_data * (1 - score)

impl: |
  expert_fns = [fn_expert0, fn_expert1]
  E2 = step.Bufferize(a=1).apply(E0)
  E3 = step.Map(fn=fn_affinity).apply(E2)
  E4 = step.Zip().apply((E2, E3))
  E5 = step.Partition(N=E_value).apply((E4, E1))
  E6 = [step.Map(fn=f).apply(s) for f, s in zip(expert_fns, E5)]
  E7 = step.Merge(fn=fn_sum).apply((E6, E1))
  return E7
